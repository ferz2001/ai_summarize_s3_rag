import os
from pathlib import Path
from typing import List
from datetime import datetime

from core.config import config
from services.qdrant_service import QdrantService
from utils.media_processing import transcribe_audio, extract_audio, summarize_text
from schemas.summary import SummaryResponse
from schemas.search import SearchResult


class SummaryService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤—ã–∂–∏–º–∫–∞–º–∏."""
    
    def __init__(self):
        self.qdrant_service = QdrantService()
    
    async def _create_summary_with_local_model(self, text: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –≤—ã–∂–∏–º–∫—É —Å –ø–æ–º–æ—â—å—é –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏–ª–∏ OpenAI."""
        return await summarize_text(text)
    
    async def create_text_summary(
        self, 
        text: str, 
        file_path: str = "manual_input"
    ) -> SummaryResponse:
        """–°–æ–∑–¥–∞–µ—Ç –≤—ã–∂–∏–º–∫—É –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
        print(f"üìù –°–æ–∑–¥–∞–Ω–∏–µ –≤—ã–∂–∏–º–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ (–¥–ª–∏–Ω–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        # –°–æ–∑–¥–∞–µ–º –≤—ã–∂–∏–º–∫—É —Å –ø–æ–º–æ—â—å—é –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
        summary = await self._create_summary_with_local_model(text)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Qdrant
        metadata = {
            "text_length": len(text),
            "model": config.LOCAL_CHAT_MODEL,
            "source": "api_text_input"
        }
        
        point_ids = await self.qdrant_service.save_summary(
            file_path=file_path,
            summary=summary,
            file_type="text",
            metadata=metadata
        )
        
        print(f"‚úÖ –í—ã–∂–∏–º–∫–∞ —Å–æ–∑–¥–∞–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ (ID: {point_ids[0]})")
        
        return SummaryResponse(
            id=point_ids[0],
            summary=summary,
            file_name=Path(file_path).name,
            file_type="text",
            chunks_count=len(point_ids),
            is_chunked=len(point_ids) > 1,
            created_at=datetime.now().isoformat()
        )
    
    async def create_audio_summary(
        self,
        file_path: str,
        file_name: str,
        language: str = "ru"
    ) -> SummaryResponse:
        """–°–æ–∑–¥–∞–µ—Ç –≤—ã–∂–∏–º–∫—É –∏–∑ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞."""
        print(f"üéµ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞: {file_name}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –≤—ã–∂–∏–º–∫—É
        existing = await self.qdrant_service.check_file_exists(file_path)
        if existing:
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –≤—ã–∂–∏–º–∫–∞ –¥–ª—è —Ñ–∞–π–ª–∞ {file_name}")
            return SummaryResponse(
                id=existing["id"],
                summary=existing["summary"],
                file_name=file_name,
                file_type="audio",
                chunks_count=existing.get("chunks_count", 1),
                is_chunked=existing.get("is_chunked", False),
                created_at=existing["created_at"]
            )
        
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ
        print("üó£Ô∏è –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ...")
        transcript = transcribe_audio(file_path, language)
        print(f"üìù –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∞ (–¥–ª–∏–Ω–∞: {len(transcript)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        # –°–æ–∑–¥–∞–µ–º –≤—ã–∂–∏–º–∫—É
        summary = await self._create_summary_with_local_model(transcript)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Qdrant
        metadata = {
            "language": language,
            "transcript_length": len(transcript),
            "model": config.LOCAL_CHAT_MODEL,
            "whisper_model": getattr(config, 'WHISPER_MODEL', 'whisper-1')
        }
        
        point_ids = await self.qdrant_service.save_summary(
            file_path=file_path,
            summary=summary,
            file_type="audio",
            metadata=metadata
        )
        
        print(f"‚úÖ –ê—É–¥–∏–æ –≤—ã–∂–∏–º–∫–∞ —Å–æ–∑–¥–∞–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        
        return SummaryResponse(
            id=point_ids[0] if len(point_ids) == 1 else f"session_{point_ids[0][:8]}",
            summary=summary,
            file_name=file_name,
            file_type="audio",
            chunks_count=len(point_ids),
            is_chunked=len(point_ids) > 1,
            created_at="2025-06-30T22:00:00"
        )
    
    async def create_video_summary(
        self,
        video_path: str,
        file_name: str,
        language: str = "ru"
    ) -> SummaryResponse:
        """–°–æ–∑–¥–∞–µ—Ç –≤—ã–∂–∏–º–∫—É –∏–∑ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞."""
        print(f"üé¨ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞: {file_name}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –≤—ã–∂–∏–º–∫—É
        existing = await self.qdrant_service.check_file_exists(video_path)
        if existing:
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –≤—ã–∂–∏–º–∫–∞ –¥–ª—è —Ñ–∞–π–ª–∞ {file_name}")
            return SummaryResponse(
                id=existing["id"],
                summary=existing["summary"],
                file_name=file_name,
                file_type="video",
                chunks_count=existing.get("chunks_count", 1),
                is_chunked=existing.get("is_chunked", False),
                created_at=existing["created_at"]
            )
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ
        print("üé¨ –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ...")
        audio_path = config.TMP_AUDIO
        extract_audio(video_path, audio_path)
        
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ
        print("üó£Ô∏è –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ...")
        transcript = transcribe_audio(audio_path, language)
        print(f"üìù –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∞ (–¥–ª–∏–Ω–∞: {len(transcript)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        # –°–æ–∑–¥–∞–µ–º –≤—ã–∂–∏–º–∫—É
        summary = await self._create_summary_with_local_model(transcript)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Qdrant
        metadata = {
            "language": language,
            "transcript_length": len(transcript),
            "model": config.LOCAL_CHAT_MODEL,
            "whisper_model": getattr(config, 'WHISPER_MODEL', 'whisper-1')
        }
        
        point_ids = await self.qdrant_service.save_summary(
            file_path=video_path,
            summary=summary,
            file_type="video",
            metadata=metadata
        )
        
        print(f"‚úÖ –í–∏–¥–µ–æ –≤—ã–∂–∏–º–∫–∞ —Å–æ–∑–¥–∞–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        
        return SummaryResponse(
            id=point_ids[0] if len(point_ids) == 1 else f"session_{point_ids[0][:8]}",
            summary=summary,
            file_name=file_name,
            file_type="video",
            chunks_count=len(point_ids),
            is_chunked=len(point_ids) > 1,
            created_at="2025-06-30T22:00:00"
        )
    
    async def search_summaries(
        self,
        query: str,
        limit: int = 5,
        min_score: float = 0.3
    ) -> List[SearchResult]:
        """–ü–æ–∏—Å–∫ –≤—ã–∂–∏–º–æ–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É."""
        print(f"üîç –ü–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}' (–º–∏–Ω. —Å—Ö–æ–∂–µ—Å—Ç—å: {min_score})")
        
        results = await self.qdrant_service.search_similar_summaries(
            query=query,
            limit=limit,
            min_score=min_score
        )
        
        search_results = [
            SearchResult(
                id=result["id"],
                score=result["score"],
                file_name=result["file_name"],
                file_type=result["file_type"],
                created_at=result["created_at"][:10],
                summary=result["summary"][:300] + "..." if len(result["summary"]) > 300 else result["summary"],
                chunks_count=result.get("chunks_count", 1),
                is_chunked=result.get("is_chunked", False)
            )
            for result in results
        ]
        
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(search_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        return search_results
    
    async def get_all_summaries(self) -> List[SummaryResponse]:
        """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –≤—ã–∂–∏–º–∫–∏."""
        print("üìö –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –≤—ã–∂–∏–º–æ–∫...")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ç–æ—á–∫–∏ –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        results = await self.qdrant_service.client.scroll(
            collection_name=self.qdrant_service.collection_name,
            limit=1000,
            with_payload=True
        )
        
        points = results[0]
        
        if not points:
            return []
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ç–æ—á–∫–∏ –ø–æ session_id –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —á–∞–Ω–∫–æ–≤
        session_groups = {}
        
        for point in points:
            payload = point.payload
            session_id = payload.get('session_id', point.id)
            
            if session_id not in session_groups:
                session_groups[session_id] = {
                    'file_name': payload.get('file_name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
                    'file_type': payload.get('file_type', 'unknown'),
                    'created_at': payload.get('created_at', ''),
                    'summary_length': payload.get('summary_length', 0),
                    'chunks': [],
                    'full_summary': payload.get('full_summary')
                }
            
            session_groups[session_id]['chunks'].append({
                'id': point.id,
                'chunk_text': payload.get('chunk_text', ''),
                'chunk_index': payload.get('chunk_index', 0),
                'is_chunk': payload.get('is_chunk', False)
            })
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        summaries = []
        for session_id, group in session_groups.items():
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º —á–∞–Ω–∫–∏ –ø–æ –∏–Ω–¥–µ–∫—Å—É
            group['chunks'].sort(key=lambda x: x['chunk_index'])
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç
            if group['full_summary']:
                summary_text = group['full_summary']
            else:
                chunk_texts = [chunk['chunk_text'] for chunk in group['chunks']]
                summary_text = self.qdrant_service._reconstruct_from_chunks(chunk_texts)
            
            summaries.append(SummaryResponse(
                id=session_id,
                summary=summary_text,
                file_name=group['file_name'],
                file_type=group['file_type'],
                chunks_count=len(group['chunks']),
                is_chunked=any(chunk['is_chunk'] for chunk in group['chunks']),
                created_at=group['created_at'][:10] if group['created_at'] else "2025-06-30"
            ))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
        summaries.sort(key=lambda x: x.created_at, reverse=True)
        
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(summaries)} –≤—ã–∂–∏–º–æ–∫")
        return summaries
    
    @staticmethod
    def cleanup_temp_file(file_path: str):
        """–£–¥–∞–ª—è–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª."""
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
                print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {file_path}")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ {file_path}: {e}")


# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
summary_service = SummaryService() 