import os
from pathlib import Path
from typing import List
from datetime import datetime
import httpx
from core.config import config
from services.qdrant_service import QdrantService
from utils.media_processing import transcribe_audio, extract_audio
from schemas.summary import SummaryResponse
from schemas.search import SearchResult
from services.local_models_service import LocalModelsService


class SummaryService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤—ã–∂–∏–º–∫–∞–º–∏."""
    
    def __init__(self):
        self.qdrant_service = QdrantService()
    
    async def _summarize_text(self, text: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø–µ—Ä–µ—Å–∫–∞–∑ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π."""
        prompt = (
            "–°–¥–µ–ª–∞–π –ø–æ–¥—Ä–æ–±–Ω—ã–π, –Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Å–∂–∞—Ç—ã–π –ø–µ—Ä–µ—Å–∫–∞–∑ —ç—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. "
            "–°–æ—Ö—Ä–∞–Ω–∏ –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ –¥–µ—Ç–∞–ª–∏ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç, –∏–∑–±–µ–≥–∞–π –ø–æ—Ç–µ—Ä–∏ –≤–∞–∂–Ω—ã—Ö —Å–º—ã—Å–ª–æ–≤. "
            "–ù–µ –¥–æ–±–∞–≤–ª—è–π —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏–ª–∏ —Ñ–æ—Ä–º–∞—Ç <think>. "
            "–í—ã–¥–∞–π —Å–≤—è–∑–Ω—ã–π, –ª–æ–≥–∏—á–Ω—ã–π –∏ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –ø–µ—Ä–µ—Å–∫–∞–∑, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–º–µ—Å—Ç–æ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞:\n\n"
            f"{text}"
        )
    
        if config.USE_LOCAL_MODELS:
            local_models = LocalModelsService()
            summary = await local_models.chat_completion([
                {
                    "role": "system",
                    "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤—ã–∂–∏–º–æ–∫. –°–æ–∑–¥–∞–≤–∞–π –∫—Ä–∞—Ç–∫–∏–µ, –Ω–æ –ø–æ–ª–Ω—ã–µ –ø–µ—Ä–µ—Å–∫–∞–∑—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ], model=config.LOCAL_CHAT_MODEL)
            print(summary)
            return summary
        else:
            async with httpx.AsyncClient(timeout=120.0) as client:
                response = await client.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers={
                        "Authorization": f"Bearer {config.OPENAI_API_KEY}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": "gpt-4o-mini",
                        "messages": [{"role": "user", "content": prompt}],
                        "max_tokens": 2000,
                        "temperature": 0.7
                    }
                )
                response.raise_for_status()
                content = response.json()["choices"][0]["message"]["content"]
                print(content)
                return content

    async def _create_summary_with_local_model(self, text: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –≤—ã–∂–∏–º–∫—É —Å –ø–æ–º–æ—â—å—é –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏–ª–∏ OpenAI."""
        return await self._summarize_text(text)
    
    async def create_text_summary(
        self, 
        text: str, 
        file_path: str = "manual_input"
    ) -> SummaryResponse:
        """–°–æ–∑–¥–∞–µ—Ç –≤—ã–∂–∏–º–∫—É –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
        print(f"üìù –°–æ–∑–¥–∞–Ω–∏–µ –≤—ã–∂–∏–º–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ (–¥–ª–∏–Ω–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        summary = await self._create_summary_with_local_model(text)
        
        metadata = {
            "text_length": len(text),
            "model": config.LOCAL_CHAT_MODEL,
            "source": "api_text_input"
        }
        
        point_ids = await self.qdrant_service.save_summary(
            file_path=file_path,
            summary=summary,
            file_type="text",
            metadata=metadata
        )
        
        print(f"‚úÖ –í—ã–∂–∏–º–∫–∞ —Å–æ–∑–¥–∞–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ (ID: {point_ids[0]})")
        
        return SummaryResponse(
            id=point_ids[0],
            summary=summary,
            file_name=Path(file_path).name,
            file_type="text",
            chunks_count=len(point_ids),
            is_chunked=len(point_ids) > 1,
            created_at=datetime.now().isoformat()
        )
    
    async def create_audio_summary(
        self,
        file_path: str,
        file_name: str,
        language: str = "ru",
        speed_multiplier: float = 2.0
    ) -> SummaryResponse:
        """–°–æ–∑–¥–∞–µ—Ç –≤—ã–∂–∏–º–∫—É –∏–∑ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞."""
        print(f"üéµ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞: {file_name}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –≤—ã–∂–∏–º–∫—É
        existing = await self.qdrant_service.check_file_exists(file_path)
        if existing:
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –≤—ã–∂–∏–º–∫–∞ –¥–ª—è —Ñ–∞–π–ª–∞ {file_name}")
            return SummaryResponse(
                id=existing["id"],
                summary=existing["summary"],
                file_name=file_name,
                file_type="audio",
                chunks_count=existing.get("chunks_count", 1),
                is_chunked=existing.get("is_chunked", False),
                created_at=existing["created_at"]
            )
        
        # –£—Å–∫–æ—Ä—è–µ–º –∞—É–¥–∏–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ, –∑–∞—Ç–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º
        audio_to_transcribe = file_path
        temp_spedup_audio = None
        
        if speed_multiplier != 1.0:
            from utils.media_processing import speed_up_audio
            import tempfile
            
            temp_spedup_audio = file_path.replace('.wav', f'_spedup_{speed_multiplier}x.wav')
            if not temp_spedup_audio.endswith('.wav'):
                temp_spedup_audio = temp_spedup_audio + '_spedup.wav'
            
            speed_up_audio(file_path, temp_spedup_audio, speed_multiplier)
            audio_to_transcribe = temp_spedup_audio
        
        try:
            print("üó£Ô∏è –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ...")
            transcript = transcribe_audio(audio_to_transcribe, language)
            print(f"üìù –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∞ (–¥–ª–∏–Ω–∞: {len(transcript)} —Å–∏–º–≤–æ–ª–æ–≤)")
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —É—Å–∫–æ—Ä–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if temp_spedup_audio and os.path.exists(temp_spedup_audio):
                import os
                os.remove(temp_spedup_audio)
        
        # –°–æ–∑–¥–∞–µ–º –≤—ã–∂–∏–º–∫—É
        summary = await self._create_summary_with_local_model(transcript)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Qdrant
        metadata = {
            "language": language,
            "transcript_length": len(transcript),
            "model": config.LOCAL_CHAT_MODEL,
            "whisper_model": getattr(config, 'WHISPER_MODEL', 'whisper-1')
        }
        
        point_ids = await self.qdrant_service.save_summary(
            file_path=file_path,
            summary=summary,
            file_type="audio",
            metadata=metadata
        )
        
        print(f"‚úÖ –ê—É–¥–∏–æ –≤—ã–∂–∏–º–∫–∞ —Å–æ–∑–¥–∞–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        
        return SummaryResponse(
            id=point_ids[0] if len(point_ids) == 1 else f"session_{point_ids[0][:8]}",
            summary=summary,
            file_name=file_name,
            file_type="audio",
            chunks_count=len(point_ids),
            is_chunked=len(point_ids) > 1,
            created_at="2025-06-30T22:00:00"
        )
    
    async def create_video_summary(
        self,
        video_path: str,
        file_name: str,
        language: str = "ru",
        speed_multiplier: float = 2.0
    ) -> SummaryResponse:
        """–°–æ–∑–¥–∞–µ—Ç –≤—ã–∂–∏–º–∫—É –∏–∑ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞."""
        print(f"üé¨ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞: {file_name}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –≤—ã–∂–∏–º–∫—É
        existing = await self.qdrant_service.check_file_exists(video_path)
        if existing:
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –≤—ã–∂–∏–º–∫–∞ –¥–ª—è —Ñ–∞–π–ª–∞ {file_name}")
            return SummaryResponse(
                id=existing["id"],
                summary=existing["summary"],
                file_name=file_name,
                file_type="video",
                chunks_count=existing.get("chunks_count", 1),
                is_chunked=existing.get("is_chunked", False),
                created_at=existing["created_at"]
            )
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ —Å —É—Å–∫–æ—Ä–µ–Ω–∏–µ–º
        print("üé¨ –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ...")
        audio_path = config.TMP_AUDIO
        extract_audio(video_path, audio_path, speed_multiplier=speed_multiplier)
        
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ (—É—Å–∫–æ—Ä–µ–Ω–∏–µ —É–∂–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–æ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏)
        print("üó£Ô∏è –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ...")
        transcript = transcribe_audio(audio_path, language)
        print(f"üìù –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∞ (–¥–ª–∏–Ω–∞: {len(transcript)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        # –°–æ–∑–¥–∞–µ–º –≤—ã–∂–∏–º–∫—É
        summary = await self._create_summary_with_local_model(transcript)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Qdrant
        metadata = {
            "language": language,
            "transcript_length": len(transcript),
            "model": config.LOCAL_CHAT_MODEL,
            "whisper_model": getattr(config, 'WHISPER_MODEL', 'whisper-1')
        }
        
        point_ids = await self.qdrant_service.save_summary(
            file_path=video_path,
            summary=summary,
            file_type="video",
            metadata=metadata
        )
        
        print(f"‚úÖ –í–∏–¥–µ–æ –≤—ã–∂–∏–º–∫–∞ —Å–æ–∑–¥–∞–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        
        return SummaryResponse(
            id=point_ids[0] if len(point_ids) == 1 else f"session_{point_ids[0][:8]}",
            summary=summary,
            file_name=file_name,
            file_type="video",
            chunks_count=len(point_ids),
            is_chunked=len(point_ids) > 1,
            created_at="2025-06-30T22:00:00"
        )
    
    async def search_summaries(
        self,
        query: str,
        limit: int = 5,
        min_score: float = 0.3
    ) -> List[SearchResult]:
        """–ü–æ–∏—Å–∫ –≤—ã–∂–∏–º–æ–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É."""
        print(f"üîç –ü–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}' (–º–∏–Ω. —Å—Ö–æ–∂–µ—Å—Ç—å: {min_score})")
        
        results = await self.qdrant_service.search_similar_summaries(
            query=query,
            limit=limit,
            min_score=min_score
        )
        
        search_results = [
            SearchResult(
                id=result["id"],
                score=result["score"],
                file_name=result["file_name"],
                file_type=result["file_type"],
                created_at=result["created_at"][:10],
                summary=result["summary"],
                chunks_count=result.get("chunks_count", 1),
                is_chunked=result.get("is_chunked", False)
            )
            for result in results
        ]
        
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(search_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        return search_results
        

    
    async def get_all_summaries(self) -> List[SummaryResponse]:
        """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –≤—ã–∂–∏–º–∫–∏."""
        print("üìö –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –≤—ã–∂–∏–º–æ–∫...")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ç–æ—á–∫–∏ –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        results = await self.qdrant_service.client.scroll(
            collection_name=self.qdrant_service.collection_name,
            limit=1000,
            with_payload=True
        )
        
        points = results[0]
        
        if not points:
            return []
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ç–æ—á–∫–∏ –ø–æ session_id –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —á–∞–Ω–∫–æ–≤
        session_groups = {}
        
        for point in points:
            payload = point.payload
            session_id = payload.get('session_id', point.id)
            
            if session_id not in session_groups:
                session_groups[session_id] = {
                    'file_name': payload.get('file_name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
                    'file_type': payload.get('file_type', 'unknown'),
                    'created_at': payload.get('created_at', ''),
                    'summary_length': payload.get('summary_length', 0),
                    'chunks': [],
                    'full_summary': payload.get('full_summary')
                }
            
            session_groups[session_id]['chunks'].append({
                'id': point.id,
                'chunk_text': payload.get('chunk_text', ''),
                'chunk_index': payload.get('chunk_index', 0),
                'is_chunk': payload.get('is_chunk', False)
            })
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        summaries = []
        for session_id, group in session_groups.items():
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º —á–∞–Ω–∫–∏ –ø–æ –∏–Ω–¥–µ–∫—Å—É
            group['chunks'].sort(key=lambda x: x['chunk_index'])
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç
            if group['full_summary']:
                summary_text = group['full_summary']
            else:
                chunk_texts = [chunk['chunk_text'] for chunk in group['chunks']]
                summary_text = self.qdrant_service._reconstruct_from_chunks(chunk_texts)
            
            summaries.append(SummaryResponse(
                id=session_id,
                summary=summary_text,
                file_name=group['file_name'],
                file_type=group['file_type'],
                chunks_count=len(group['chunks']),
                is_chunked=any(chunk['is_chunk'] for chunk in group['chunks']),
                created_at=group['created_at'][:10] if group['created_at'] else "2025-06-30"
            ))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
        summaries.sort(key=lambda x: x.created_at, reverse=True)
        
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(summaries)} –≤—ã–∂–∏–º–æ–∫")
        return summaries
    
    @staticmethod
    def cleanup_temp_file(file_path: str):
        """–£–¥–∞–ª—è–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª."""
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
                print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {file_path}")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ {file_path}: {e}")


# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
summary_service = SummaryService() 