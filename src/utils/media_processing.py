import subprocess
import time

from faster_whisper import WhisperModel


def extract_audio(video_path: str, audio_path: str, speed_multiplier: float = 1.0) -> None:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–≤—É–∫–æ–≤—É—é –¥–æ—Ä–æ–∂–∫—É –≤ 16kHz –º–æ–Ω–æ WAV —Å –ø–æ–º–æ—â—å—é ffmpeg.
    
    Args:
        video_path: –ü—É—Ç—å –∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—É
        audio_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—É–¥–∏–æ
        speed_multiplier: –ú–Ω–æ–∂–∏—Ç–µ–ª—å —Å–∫–æ—Ä–æ—Å—Ç–∏ (2.0 = 2x –±—ã—Å—Ç—Ä–µ–µ, 0.5 = 2x –º–µ–¥–ª–µ–Ω–Ω–µ–µ)
    """
    command = [
        "ffmpeg",
        "-i",
        video_path,
        "-vn",
        "-acodec",
        "pcm_s16le",
        "-ar",
        "16000",
        "-ac",
        "1"
    ]
    
    # –î–æ–±–∞–≤–ª—è–µ–º —É—Å–∫–æ—Ä–µ–Ω–∏–µ, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if speed_multiplier != 1.0:
        print(f"‚ö° –£—Å–∫–æ—Ä—è—é –∞—É–¥–∏–æ –≤ {speed_multiplier}x —Ä–∞–∑ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        command.extend(["-filter:a", f"atempo={speed_multiplier}"])
    
    command.extend([audio_path, "-y"])
    subprocess.run(command, check=True)


def speed_up_audio(input_path: str, output_path: str, speed_multiplier: float = 2.0) -> None:
    """
    –£—Å–∫–æ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∞—É–¥–∏–æ—Ñ–∞–π–ª.
    
    Args:
        input_path: –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –∞—É–¥–∏–æ—Ñ–∞–π–ª—É
        output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —É—Å–∫–æ—Ä–µ–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ
        speed_multiplier: –ú–Ω–æ–∂–∏—Ç–µ–ª—å —Å–∫–æ—Ä–æ—Å—Ç–∏ (2.0 = 2x –±—ã—Å—Ç—Ä–µ–µ)
    """
    print(f"‚ö° –£—Å–∫–æ—Ä—è—é –∞—É–¥–∏–æ –≤ {speed_multiplier}x —Ä–∞–∑...")
    command = [
        "ffmpeg",
        "-i",
        input_path,
        "-filter:a",
        f"atempo={speed_multiplier}",
        "-acodec",
        "pcm_s16le",
        "-ar",
        "16000",
        "-ac",
        "1",
        output_path,
        "-y"
    ]
    subprocess.run(command, check=True)


def transcribe_audio(audio_path: str, language: str = "ru") -> str:
    """
    –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ—Ñ–∞–π–ª —Å –ø–æ–º–æ—â—å—é Whisper.
    Args:
        audio_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É.
        language: –Ø–∑—ã–∫ –∞—É–¥–∏–æ.
    Returns:
        –¢–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏.
    """
    print(f"üó£Ô∏è –ù–∞—á–∏–Ω–∞—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∞—É–¥–∏–æ: {audio_path}")
    start_time = time.time()
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å Whisper
    model = WhisperModel("small", device="cpu", compute_type="int8")
    
    segments, info = model.transcribe(
        audio_path, 
        language=language,
        condition_on_previous_text=False,
        word_timestamps=False
    )
    
    transcript = " ".join([segment.text for segment in segments])
    
    print(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {time.time() - start_time:.1f}—Å")
    print(f"üìù –ü–æ–ª—É—á–µ–Ω–æ {len(transcript)} —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞")
    
    return transcript.strip()
