import asyncio

from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent

from core.config import config

llm = ChatOpenAI(openai_api_key=config.OPENAI_API_KEY, model="gpt-4o-mini")

client = MultiServerMCPClient(
    {
        "local_http_tools": {
            "url": "http://localhost:9000/mcp/",
            "transport": "streamable_http",
        }
    }
)

async def main():
    print("‚è≥ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MCP —Å–µ—Ä–≤–µ—Ä—É –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤...")
    tools = await client.get_tools()
    print("‚úÖ –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –ø–æ–ª—É—á–µ–Ω—ã:", [tool.name for tool in tools])

    agent = create_react_agent(llm, tools)

    # # –°–æ–∑–¥–∞–µ–º –≤—ã–∂–∏–º–∫—É –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Qdrant
    # prompt = "–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫—É—é –≤—ã–∂–∏–º–∫—É –∏–∑ —Ñ–∞–π–ª–∞ `video5m.mp4` –∏ —Å–æ—Ö—Ä–∞–Ω–∏ –µ—ë –≤ Qdrant."
    # print(f"\n‚ñ∂Ô∏è  –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∞–≥–µ–Ω—Ç—É: '{prompt}'")

    # response = await agent.ainvoke({"messages": [("user", prompt)]})

    # print("\n--- –û—Ç–≤–µ—Ç –∞–≥–µ–Ω—Ç–∞ ---")
    # final_response = response["messages"][-1]
    # if hasattr(final_response, "content"):
    #     print(final_response.content)
    # print("--------------------")
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
    print("\nüîç –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ –≤ Qdrant...")
    search_prompt = "–ù–∞–π–¥–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø—Ä–æ –ø–ª–∞—Ç—Ñ–æ—Ä–º—É —Ç–µ—Ö–Ω–∏—É–º —á—Ç–æ–±—ã —Å—Ö–æ–∂–µ—Å—Ç—å –±—ã–ª–∞ –±–æ–ª—å—à–µ 0.1"
    print(f"\n‚ñ∂Ô∏è  –ü–æ–∏—Å–∫: '{search_prompt}'")
    
    search_response = await agent.ainvoke({"messages": [("user", search_prompt)]})
    
    print("\n--- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ ---")
    search_final = search_response["messages"][-1]
    if hasattr(search_final, "content"):
        print(search_final.content)
    print("-------------------------")


if __name__ == "__main__":
    asyncio.run(main())
